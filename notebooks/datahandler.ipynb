{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "audio_files = \"./../data/raw\"\n",
    "\n",
    "dir = os.walk(audio_files, topdown=True)\n",
    "\n",
    "labels_raw = next(iter(dir))[1]\n",
    "labels_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_names = []\n",
    "labels_idx = []\n",
    "\n",
    "for label in labels_raw:\n",
    "    idx, name = label.split(\"_\", 1)\n",
    "    label_names.append(name)\n",
    "    labels_idx.append(int(idx))\n",
    "\n",
    "\n",
    "label_names = np.array(label_names)\n",
    "labels_idx = np.array(labels_idx)\n",
    "\n",
    "label_names = label_names[labels_idx.argsort()]\n",
    "labels_idx.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"mid\": label_names,\n",
    "    \"display_name\": label_names\n",
    "}, index=labels_idx)\n",
    "\n",
    "df.to_csv(\"./../data/processed/class_labels_indices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "import re\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.signal import resample_poly\n",
    "import json\n",
    "\n",
    "dir = os.walk(audio_files, topdown=True)\n",
    "next(iter(dir))[1]\n",
    "\n",
    "\n",
    "# CREATE TRAIN, VAL, TEST data \n",
    "# Based on songs so they don't leak \n",
    "data = []\n",
    "supported_exts = ('.wav', '.flac', '.ogg', '.aiff', '.au', '.mp3', '.m4a', '.wma')\n",
    "\n",
    "def create_samples(samples, data_split=\"train\", remove_intros_outros=True):\n",
    "\n",
    "    for file in samples:\n",
    "        makedirs(f'./../data/processed/{data_split}', exist_ok=True)\n",
    "        \n",
    "        if not file.lower().endswith(supported_exts):\n",
    "            print(\"SKIP\")\n",
    "            continue\n",
    "\n",
    "        wav, sr = librosa.load(path + '/' + str(file))\n",
    "        \n",
    "        prev_samples_to_take = 0\n",
    "        samples_to_take = 10*sr\n",
    "\n",
    "        samples = []\n",
    "\n",
    "        while samples_to_take < wav.shape[0]:\n",
    "            samples.append(wav[prev_samples_to_take:samples_to_take])\n",
    "            prev_samples_to_take = samples_to_take\n",
    "            samples_to_take += 10*sr\n",
    "\n",
    "        if remove_intros_outros:\n",
    "            # Remove first and last 3 samples due to intro and outros\n",
    "            samples = samples[3:]\n",
    "            samples = samples[:-3]\n",
    "\n",
    "        for idx, sample in enumerate(samples):\n",
    "            # skip intros\n",
    "            if idx == 0 or idx == 1:\n",
    "                continue\n",
    "\n",
    "            # Split the songs into 10 second segments\n",
    "            save_path = str(f'./../data/processed/{data_split}')\n",
    "\n",
    "\n",
    "            output_path = save_path + '/'  + str(idx) + '-'  + (re.sub(r\"[^A-Za-z\\.\\d]\", \"\", str(file))).lower()\n",
    "            # output_path = re.sub(r'[A-Z\\s]', \"\", output_path)\n",
    "            some_json =  {\n",
    "                \"wav\": output_path,\n",
    "                \"labels\": str(label),\n",
    "                \"split\": data_split\n",
    "            }\n",
    "\n",
    "            data.append(some_json)\n",
    "\n",
    "            resampled = resample_poly(sample, 16000, sr)\n",
    "\n",
    "\n",
    "            sf.write(output_path, resampled, 16000)\n",
    "\n",
    "\n",
    "for files in dir:\n",
    "    label = \"\"\n",
    "    for name in label_names:\n",
    "        if name in files[0]:\n",
    "            label = name\n",
    "\n",
    "\n",
    "    path = files[0]\n",
    "    arr = np.array(files[2])\n",
    "\n",
    "    n_arr = arr.shape[0]\n",
    "    # Approx 10% val, 10% test\n",
    "    split_proportion = 0.1 \n",
    "\n",
    "    split_int = int(np.round(n_arr*split_proportion))\n",
    "\n",
    "    np.random.shuffle(arr)\n",
    "\n",
    "    test_split = arr[:split_int]\n",
    "    val_split = arr[split_int:split_int*2]\n",
    "    train_split = arr[split_int*2:]\n",
    "\n",
    "    create_samples(test_split, \"test\")\n",
    "    create_samples(val_split, \"val\")\n",
    "    create_samples(train_split, \"train\")\n",
    "\n",
    "traindata_json = {\"data\": data}\n",
    "\n",
    "with open(\"./../data/processed/train_test_val_data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(traindata_json))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
